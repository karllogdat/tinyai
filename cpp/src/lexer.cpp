#include "./lexer.hpp"
#include <cstdio>
#include <fstream>
#include <iostream>

void TableDrivenLexer::lex(const std::string &input)
{
  int startState = transitionTable.startStateId;
  int currentPos = 0;
  int tokenStart = 0; // Track where current token started

  while (currentPos <= input.size()) { // Changed to <= to handle last token
    int currentState = startState;
    int lastAcceptState = -1;
    int lastAcceptPos = -1;

    // Try to match longest possible token from current position
    int pos = tokenStart;
    while (pos < input.size()) {
      char c = input[pos];

      // Check if character is in alphabet
      auto symbolIt = transitionTable.symbolToId.find(c);
      if (symbolIt == transitionTable.symbolToId.end()) {
        break;
      }

      int nextState = transitionTable.table[currentState][symbolIt->second];
      if (nextState == -1) {
        break;
      }

      currentState = nextState;
      if (transitionTable.acceptStateIds.count(currentState)) {
        lastAcceptState = currentState;
        lastAcceptPos = pos;
      }
      pos++;
    }

    // Emit token if we found an accepting state
    if (lastAcceptState != -1) {
      int lexemeLength = lastAcceptPos - tokenStart + 1;
      std::string lexeme = input.substr(tokenStart, lexemeLength);
      std::string tokenType = transitionTable.stateTokenTypes[lastAcceptState];

      tokens.push_back(LexerToken(lexeme, tokenType));

      if (tokenType != "WHITESPACE") { // Skip whitespace tokens
        std::cout << "Token: " << tokenType << ", Lexeme: \"" << lexeme << "\""
                  << std::endl;
      }

      tokenStart = lastAcceptPos + 1;
      currentPos = tokenStart;
    } else {
      // No valid token found - skip one character
      if (tokenStart < input.size()) {
        // add invalid (unknown token) to tokens
        std::string lexeme(1, input[tokenStart]);
        std::string tokenType = "UNKNOWN";
        tokens.emplace_back(lexeme, tokenType);

        std::cerr << "Invalid input at position " << tokenStart << ": '"
                  << input[tokenStart] << "'" << std::endl;
        tokenStart++;
        currentPos = tokenStart;
      } else {
        break;
      }
    }
  }
}

void TableDrivenLexer::createSymbolTable(const std::string &input,
                                         const std::string &file,
                                         bool printWhitespace)
{
  // ensure that token list is generated by calling lex()
  lex(input);

  FILE *symbolTableFile;
  symbolTableFile = fopen(file.c_str(), "w");

  if (symbolTableFile == NULL) {
    perror("error opening symbol table file");
    return;
  }

  fprintf(symbolTableFile, "%-30s %s\n", "LEXEME", "TOKEN");
  for (const auto &token : tokens) {
    if (token.type == "WHITESPACE" && !printWhitespace)
      continue;

    fprintf(symbolTableFile,
            "%-30s %s\n",
            token.lexeme.c_str(),
            token.type.c_str());
  }

  fclose(symbolTableFile);
}